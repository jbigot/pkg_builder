#!/usr/bin/env python3

import atexit
from concurrent.futures import ThreadPoolExecutor, wait, FIRST_COMPLETED
from hashlib import sha256
import json
from os import cpu_count, link
from pathlib import Path
import re
import socket
from shutil import copy2, copytree, rmtree
from subprocess import Popen, CalledProcessError, PIPE, STDOUT
from sys import argv, stderr
from tempfile import mkdtemp, TemporaryDirectory
from time import sleep
from typing import Iterable, Set
from urllib.error import URLError
from urllib.request import url2pathname, urlopen

from debian.changelog import Changelog, format_date
from debian.deb822 import Deb822, _PkgRelationMixin
import yaml

from distinfo import ReleaseInfo, distributions

PARALLELISM = cpu_count() + 1
VERBOSE = False
INTERACTIVE = True
PASSPHRASE = ""


class GpgInfo:
    def __init__(self, base_dir, cfg):
        self.secring = base_dir / cfg.get('gpg', {}).get('file', 'key.gpg')
        self.key = cfg.get('gpg', {}).get('id', None)
        self.passphrase = PASSPHRASE


RUNNING_PROCESSES = set()
TERMINATE_REQUEST = False


class CancellationException(Exception):
    pass


def cancellation_point():
    if TERMINATE_REQUEST:
        raise CancellationException('Termination request received')


def cancellation_request():
    global TERMINATE_REQUEST
    TERMINATE_REQUEST = True
    for process in RUNNING_PROCESSES:
        if process.poll() is None:
            process.terminate()


def cheched_run(cmd, cwd=None, return_stdout=False):
    with TemporaryDirectory() as tmp:
        if cwd is None:
            cwd = tmp
        err = STDOUT
        if VERBOSE:
            out = None
            print("$ " + ' '.join([str(c) for c in cmd]))
        else:
            out = PIPE
        if return_stdout:
            err = out
            out = PIPE
        cancellation_point()
        with Popen(cmd, cwd=cwd, stdout=out, stderr=err, encoding='UTF8') as process:
            try:
                RUNNING_PROCESSES.add(process)
                out, err = process.communicate()
            except BaseException:
                process.kill()
                raise
            finally:
                RUNNING_PROCESSES.remove(process)
                cancellation_point()
            retcode = process.poll()
            if retcode:
                raise CalledProcessError(retcode, process.args, output=out, stderr=err)
            if return_stdout:
                if VERBOSE:
                    print(out, end='')
                return out
    return None


DOWNLOADED = {}
DOWNLOAD_DIR = Path(mkdtemp(prefix='DOWNLOAD_DIR.'))
atexit.register(rmtree, DOWNLOAD_DIR)


def download(url, path):
    cancellation_point()
    if url in DOWNLOADED:
        while DOWNLOADED[url] is None:
            sleep(0.1)
            cancellation_point()
            if VERBOSE:
                print("Downloading " + url + " : in cache!")
    else:
        DOWNLOADED[url] = None
        temp_path = DOWNLOAD_DIR / sha256(bytes(url, 'UTF8')).hexdigest()
        if VERBOSE:
            print("Downloading " + url + " ...")
        for timeout in [1, 2, 3, 5, 7]:
            try:
                with urlopen(url, timeout=timeout) as raw_src, temp_path.open('wb') as raw_dst:
                    raw_dst.write(raw_src.read())
                break
            except URLError as err:
                if timeout == 7:
                    raise URLError('while downloading ' + url + ': ' + str(err))
            except socket.timeout as err:
                if timeout == 7:
                    raise URLError('while downloading ' + url + ': ' + str(err))
        if VERBOSE:
            print("Downloading " + url + " done!")
        DOWNLOADED[url] = temp_path
    try:
        link(DOWNLOADED[url], path)
    except OSError:
        copy2(DOWNLOADED[url], path)


class Control(Deb822, _PkgRelationMixin):
    _relationship_fields = ['build-depends',
                            'build-depends-indep', 'build-depends-arch']

    def __init__(self, *args, **kwargs):
        Deb822.__init__(self, *args, **kwargs)
        _PkgRelationMixin.__init__(self, *args, **kwargs)


class DebPackageBuilder:
    def __init__(self, tmp_dir: Path, dist_release: ReleaseInfo, base_dir: Path, gpg_info: GpgInfo,
                 name: str, pkg_data: dict):
        self._tmp_dir = tmp_dir / (name + '.' + dist_release.uid() + '.deb-build')
        self.dist_release = dist_release
        self._gpg_info = gpg_info
        self._name = name
        self._debian_dir = pkg_data.get('debian', None)
        self._orig_url = pkg_data.get('orig', None)
        self._finished = False
        self._depends = set([self])  # self depend => never ready
        self.outdir = self._tmp_dir / 'output'
        self.bin_provides = set()
        self.bin_depends = set()

        if self._debian_dir is None:
            return

        self._debian_dir = base_dir / self._debian_dir

        deps_kind = ['build-depends', 'build-depends-indep', 'build-depends-arch']
        with (self._debian_dir / 'control').open() as raw_control:
            control_paragraphs = Deb822.iter_paragraphs(
                raw_control, strict={'whitespace-separates-paragraphs': False})
            self.bin_provides = {pkg['Package'] for
                                 pkg in control_paragraphs if 'Package' in pkg}
        with (self._debian_dir / 'control').open() as raw_control:
            control = Control(raw_control)
            self.bin_depends = {om['name'] for
                                dl in deps_kind for am in control.relations[dl] for om in am}

    def ready(self):
        return all(map(DebPackageBuilder.finished, self._depends))

    def finished(self):
        return self._finished

    def __dep_packages(self):
        return {e for el in self._depends for e in el.__dep_packages()} | set([self])

    def build(self):
        cancellation_point()
        try:
            print("\033[34m[STARTED]\033[39m * building deb for " +
                  self._name + ' on ' + str(self.dist_release) + "...")

            if self._debian_dir is None:
                self._finished = True
                print("\033[36m[SKIPPED]\033[39m * building deb for " +
                      self._name + ' on ' + str(self.dist_release) + "!")
                return

            # Setup our directories
            self._tmp_dir.mkdir()
            self.outdir.mkdir()
            pkg_dir = self._tmp_dir / 'pkg'
            pkg_dir.mkdir()
            debian_dir = Path(copytree(self._debian_dir, pkg_dir / 'debian'))

            # Add the bpo to the version string
            with (debian_dir / 'changelog').open() as raw_changelog:
                changelog = Changelog(raw_changelog)
            target_releases = set()
            for tgt in changelog.distributions.split(' '):
                target_releases |= set(self.dist_release.distrib.releases(
                    codename=re.sub(r'-backports.*', '', tgt)))
                target_releases |= set(self.dist_release.distrib.releases(
                    suite=re.sub(r'-backports.*', '', tgt)))
            if len(target_releases) > 0 and self.dist_release < min(target_releases):
                changelog.new_block(
                    package=changelog.package,
                    version=str(changelog.version) + '~bpo' + self.dist_release.id,
                    distributions=self.dist_release.codename,
                    urgency=changelog.urgency,
                    changes=['  * Backport rebuild for ' +
                             str(self.dist_release)],
                    author=changelog.author,
                    date=format_date())
                with (debian_dir / 'changelog').open('w') as raw_changelog:
                    changelog.write_to_open_file(raw_changelog)
            elif self.dist_release not in target_releases:
                self._finished = True
                print("\033[36m[SKIPPED]\033[39m * building deb for " +
                      self._name + ' on ' + str(self.dist_release) + "!")
                return

            # Download the orig file
            self._orig_url = self._orig_url.format(
                upstream_version=changelog.upstream_version, package=changelog.package)
            download(self._orig_url,
                     pkg_dir / (
                         changelog.package + '_' + changelog.upstream_version
                         + '.orig.tar' + (Path(url2pathname(self._orig_url)).suffix)))

            # Generate the dependencies .deb
            deps_dir = self._tmp_dir / 'deps'
            deps_dir.mkdir()
            cheched_run(['mk-build-deps', '-P' + self.dist_release.distrib.id + ',' +
                         self.dist_release.codename, pkg_dir / 'debian' / 'control'], cwd=deps_dir)

            # Build a repo with all dependencies
            localrepo = self._tmp_dir / 'repo'
            build_deb_repo(self._tmp_dir, self.__dep_packages(),
                           self._gpg_info, localrepo)

            # Build the package in docker
            cheched_run(['docker', 'run', '--rm', '-eDH_VERBOSE=1',
                         '--mount', 'type=bind,source=' +
                         str(pkg_dir) + ',target=/src',
                         '--mount', 'type=bind,source=' +
                         str(deps_dir) + ',target=/deps',
                         '--mount', 'type=bind,source=' +
                         str(localrepo / self.dist_release.distrib.id) +
                         ',target=/localrepo',
                         '--tmpfs', '/tmp:exec',
                         'pdidevel/' + self.dist_release.distrib.id +
                         '_builder:' + self.dist_release.codename,
                         '-j8', '-sa', '-P' + self.dist_release.distrib.id +
                         ',' + self.dist_release.codename
                         ])

            # Signing the generated packages
            gpg_kr = self._tmp_dir / 'gpg-kr'
            (self._tmp_dir / 'gnupg').mkdir(0o700)
            cheched_run(['gpg2',
                         '--batch',
                         '--homedir',
                         str(self._tmp_dir / 'gnupg'),
                         '--passphrase',
                         self._gpg_info.passphrase,
                         '--import',
                         self._gpg_info.secring],
                        cwd=pkg_dir)
            with gpg_kr.open('w') as gpg_kr_raw:
                print('#!/bin/sh', file=gpg_kr_raw)
                print('exec gpg2 --batch --homedir "' + str(self._tmp_dir / 'gnupg') +
                      '" --passphrase "' + self._gpg_info.passphrase + '" "$@"', file=gpg_kr_raw)
            gpg_kr.chmod(0o777)
            cmd = ['debsign', '--no-conf', '-p' +
                   str(gpg_kr), '--debs-dir', str(pkg_dir)]
            if self._gpg_info.key is not None:
                cmd.append('-k' + self._gpg_info.key)
            cheched_run(cmd, cwd=pkg_dir)

            # Moving the generated packages to the output directory
            for file in pkg_dir.iterdir():
                if file.is_file():
                    file.rename(self.outdir / file.name)

            self._finished = True
            print("\033[32m[SUCCESS]\033[39m * building deb for " +
                  self._name + ' on ' + str(self.dist_release) + "!")
        except CancellationException:
            print("\033[33m[CANCEL]\033[39m  * building deb for " +
                  self._name + ' on ' + str(self.dist_release) + "!")
            raise
        except BaseException:
            print("\033[31m[FAILURE]\033[39m * building deb for " +
                  self._name + ' on ' + str(self.dist_release) + "!")
            raise


def build_deb_repo(tmp_dir, pkgs, gpg_info: GpgInfo, output_dir):

    pkgs = list(
        filter(lambda p: 'debian' in p.dist_release.distrib.id_like, pkgs))
    if len(pkgs) == 0:
        return

    tmp_dir = tmp_dir / 'aptly'
    tmp_dir.mkdir()
    aptly_confpath = tmp_dir / 'aptly.conf'

    def aptly(*args):
        cheched_run(['aptly', '-config=' + str(aptly_confpath)] + list(args))

    aptly_cfg = {
        'architectures': ["amd64", "source"],
        'gpgProvider': "internal",
        'rootDir': str(tmp_dir),
        'FileSystemPublishEndpoints': {'default': {
            'rootDir': str(output_dir),
            'linkMethod': "copy",
        }},
    }
    with aptly_confpath.open('w') as aptly_conf:
        json.dump(aptly_cfg, aptly_conf)

    output_dir.mkdir(parents=True, exist_ok=True)

    repos = set()
    for pkg in pkgs:
        if pkg.dist_release not in repos:
            repos.add(pkg.dist_release)
            aptly('repo', 'create', '-distribution=' +
                  pkg.dist_release.codename, pkg.dist_release.uid())
            if pkg.dist_release.suite is not None:
                aptly('repo', 'create', '-distribution=' + pkg.dist_release.suite,
                      pkg.dist_release.uid() + ':' + pkg.dist_release.suite)
        aptly('repo', 'include',
              # '-keyring='+str(gpg_info.pubring),
              '-keyring=' + str(gpg_info.secring),
              '-no-remove-files', '-repo=' + pkg.dist_release.uid(), str(pkg.outdir))
        if pkg.dist_release.suite is not None:
            aptly('repo', 'include',
                  # '-keyring='+str(gpg_info.pubring),
                  '-keyring=' + str(gpg_info.secring),
                  '-no-remove-files',
                  '-repo=' + pkg.dist_release.uid() + ':' + pkg.dist_release.suite, str(pkg.outdir))
    for dist_release in repos:
        publish_repo = ['publish', 'repo',
                        # '-keyring='+str(gpg_info.pubring),
                        '-secret-keyring=' + str(gpg_info.secring)]
        if gpg_info.key is not None:
            publish_repo.append('-gpg-key=' + gpg_info.key[-8:])
        if gpg_info.passphrase != '':
            publish_repo.append('-passphrase=' + gpg_info.passphrase)
        aptly(*publish_repo, dist_release.uid(),
              'filesystem:default:' + dist_release.distrib.id)
        if dist_release.suite is not None:
            aptly(*publish_repo, dist_release.uid() + ':' + dist_release.suite,
                  'filesystem:default:' + dist_release.distrib.id)


class RpmPackageBuilder:
    def __init__(
            self,
            tmp_dir: Path,
            dist_release: ReleaseInfo,
            base_dir: Path,
            gpg_info: GpgInfo,
            name: str,
            pkg_data: dict):
        self._tmp_dir = tmp_dir / (name + '.' + dist_release.uid() + '.rpm-build')
        self.dist_release = dist_release
        self._gpg_info = gpg_info
        self._name = name
        self._spec = pkg_data.get('spec')
        self._finished = False
        self._depends = set([self])  # self depend => never ready
        self.outdir = self._tmp_dir / 'output'
        self.bin_provides = set()
        self.bin_depends = set()

        for relation, comparator in {'after': ReleaseInfo.__ge__,
                                     'before': ReleaseInfo.__le__,
                                     'equal': ReleaseInfo.__eq__}.items():
            for cmp_release in release_list(pkg_data.get('disable', {}).get(relation, {})):
                if comparator(self.dist_release, cmp_release):
                    self._spec = None

        if self._spec is None:
            return

        self._spec = base_dir / self._spec

        self.bin_depends = {re.sub(r'[\( ].*', '', dep) for dep in
                            cheched_run(['rpmspec', '--buildrequires', '-q', str(self._spec)],
                                        return_stdout=True).splitlines()}
        self.bin_provides = {re.sub(r'[\( ].*', '', d) for d in
                             cheched_run(['rpmspec', '--provides', '-q', str(self._spec)],
                                         return_stdout=True).splitlines()}

    def ready(self):
        return all(map(RpmPackageBuilder.finished, self._depends))

    def finished(self):
        return self._finished

    def incomings(self):
        return {e for el in self._depends for e in el.incomings()} | set([self])

    def build(self):
        cancellation_point()
        try:
            print("\033[34m[STARTED]\033[39m * building rpm for " +
                  self._name + ' on ' + str(self.dist_release) + "...")

            if self._spec is None:
                self._finished = True
                print("\033[36m[SKIPPED]\033[39m * building rpm for " +
                      self._name + ' on ' + str(self.dist_release) + "!")
                return

            # Setup our directories
            self._tmp_dir.mkdir()
            self.outdir.mkdir()
            pkg_dir = self._tmp_dir / 'pkg'
            pkg_dir.mkdir()
            spec = pkg_dir / self._spec.name
            copy2(self._spec, spec)

            localrepo = self._tmp_dir / 'repo'
            build_rpm_repo(self._tmp_dir, self.incomings(),
                           self._gpg_info, localrepo)

            cheched_run(['docker', 'run', '--rm', '--mount', 'type=bind,source=' +
                         str(pkg_dir) +
                         ',target=/src', '--mount', 'type=bind,source=' +
                         str(localrepo /
                             self.dist_release.distrib.id /
                             self.dist_release.id) +
                         ',target=/localrepo', '--tmpfs', '/tmp:exec', 'pdidevel/' +
                         self.dist_release.distrib.id +
                         '_builder:' +
                         self.dist_release.id])

            for file in pkg_dir.iterdir():
                if file.suffix == '.rpm':
                    file.rename(self.outdir / file.name)

            print("\033[32m[SUCCESS]\033[39m * building rpm for " +
                  self._name + ' on ' + str(self.dist_release) + "!")
            self._finished = True
        except CancellationException:
            print("\033[33m[CANCEL]\033[39m  * building rpm for " +
                  self._name + ' on ' + str(self.dist_release) + "!")
            raise
        except BaseException:
            print("\033[31m[FAILURE]\033[39m * building rpm for " +
                  self._name + ' on ' + str(self.dist_release) + "!")
            raise


def build_rpm_repo(tmp_dir, pkgs: Iterable[RpmPackageBuilder], _: GpgInfo, output_dir: Path):

    pkgs = list(
        filter(lambda p: 'fedora' in p.dist_release.distrib.id_like, pkgs))
    if len(pkgs) == 0:
        return

    tmp_dir = tmp_dir / 'createrepo'
    tmp_dir.mkdir()

    release_dir_set = set()
    output_dir.mkdir(parents=True, exist_ok=True)
    for pkg in pkgs:
        if not pkg.outdir.is_dir():
            continue
        release_dir = output_dir / pkg.dist_release.distrib.id / pkg.dist_release.id
        release_dir.mkdir(parents=True, exist_ok=True)
        for file in pkg.outdir.iterdir():
            if file.suffix == '.rpm' and len(file.suffixes) >= 2:
                release_dir_set.add(release_dir)
                rpmdir = release_dir / file.suffixes[-2][1:]
                rpmdir.mkdir(exist_ok=True)
                try:
                    link(file, rpmdir / file.name)
                except OSError:
                    copy2(file, rpmdir / file.name)

    for release_dir in release_dir_set:
        cheched_run(['createrepo', '.'], cwd=release_dir)


def order_packages(pkglst):
    # maps (b, r) => s when the binary package b is generated by the source package s on release r
    providers = {(bpkg, pkg.dist_release): pkg for pkg in pkglst for bpkg in pkg.bin_provides}
    for pkg in pkglst:
        pkg._depends = {providers[(b, pkg.dist_release)] for b in pkg.bin_depends if (
            b, pkg.dist_release) in providers}


def release_list(cfg: dict) -> Set[ReleaseInfo]:
    releases = set()
    for dist_id, release_id_lst in cfg.items():
        dist = next(distributions(id=dist_id))
        if not isinstance(release_id_lst, list):
            release_id_lst = [release_id_lst]
        for release_id in release_id_lst:
            if release_id == 'supported':
                releases.update(dist.releases(supported=True))
            else:
                releases.update(dist.releases(codename=release_id))
                releases.update(dist.releases(suite=release_id))
                releases.update(dist.releases(id=release_id))
    return releases


def package_list(packages_cfg: dict, releases: Set[ReleaseInfo], tmp_dir: Path, base_dir: Path, gpg_info: GpgInfo) -> set:
    packages = set()
    for name, pkg_cfg in packages_cfg.items():
        for dist_release in releases:
            if 'debian' in dist_release.distrib.id_like:
                packages.add(
                    DebPackageBuilder(tmp_dir, dist_release, base_dir, gpg_info, name, pkg_cfg))
            if 'fedora' in dist_release.distrib.id_like:
                packages.add(
                    RpmPackageBuilder(tmp_dir, dist_release, base_dir, gpg_info, name, pkg_cfg))
    order_packages(packages)
    return packages


def build_packages(cfg_path):
    base_dir = cfg_path.parent.absolute()
    tmp_dir = Path(mkdtemp(prefix='PKGBUILD.'))
    atexit.register(rmtree, tmp_dir)
    with cfg_path.open('r') as cfg_file:
        cfg = yaml.safe_load(cfg_file)
    releases = release_list(cfg['distribs'])

    gpg_info = GpgInfo(base_dir, cfg)
    packages = package_list(cfg['packages'], releases, tmp_dir, base_dir, gpg_info)

    with ThreadPoolExecutor(max_workers=PARALLELISM) as executor:
        try:
            in_progress = set()
            waiting = set(packages)
            while (len(waiting) + len(in_progress)) > 0:
                for pkg_cfg in {pkg_cfg for pkg_cfg in waiting if pkg_cfg.ready()}:
                    waiting.remove(pkg_cfg)
                    in_progress.add(executor.submit(pkg_cfg.build))
                if len(in_progress) == 0:
                    raise Exception('Invalid scheduling: no task ready')
                done, in_progress = wait(
                    in_progress, return_when=FIRST_COMPLETED)
                for done_pkg in done:
                    done_pkg.result()
        except BaseException:
            executor.shutdown(False)
            print(
                "\033[33m[WARNING]\033[39m * Asking remaining tasks to terminate...")
            cancellation_request()
            raise

        output_path = base_dir / cfg.get('repository', {}).get('path', 'repositories')
        build_deb_repo(tmp_dir, packages, gpg_info, output_path)
        build_rpm_repo(tmp_dir, packages, gpg_info, output_path)


def main():
    try:
        base_dir = Path.cwd().absolute()

        if len(argv) > 2:
            print('Usage : ' + argv[0] + ' [<build.conf>]')

        if len(argv) < 2:
            cfg_path = base_dir / 'build.conf'
        else:
            cfg_path = base_dir / argv[-1]

        build_packages(cfg_path)
    except CalledProcessError as err:
        print("\033[31m[ERROR]\033[39m   * Error while running subprocess:\n$ " +
              ' '.join([str(ce) for ce in err.cmd]), file=stderr)
        if err.stdout is not None:
            print(err.stdout)
        if err.stderr is not None:
            print(err.stderr, file=stderr)
        print(file=stderr)
        if INTERACTIVE:
            input("Press Enter to clean-up and quit...")
        raise
    except Exception as err:
        print("\033[31m[ERROR]\033[39m   * " + str(err))
        if INTERACTIVE:
            input("Press Enter to clean-up and continue...")
        raise


if __name__ == '__main__':
    main()
